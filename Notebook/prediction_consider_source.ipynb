{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c826f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from tqdm import trange\n",
    "from sklearn.linear_model import Ridge  \n",
    "import warnings, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e646596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Trump_First_Term.csv')\n",
    "df = df.sort_values([\"Year\", \"Month\", \"Source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9627fab",
   "metadata": {},
   "source": [
    "| Feature                        | Why it matters                                                 | How to compute                                   |\n",
    "| ------------------------------ | -------------------------------------------------------------- | ------------------------------------------------ |\n",
    "| `t` ‚Äî running month index      | Captures secular trend across both terms.                      | `(Year-2017)*12 + Month - 1`                     |\n",
    "| `sin_month`, `cos_month`       | Seasonality (cyclic month‚Äëof‚Äëyear).                            | `sin(2œÄ¬∑Month/12)`,¬†`cos(‚Ä¶)`                     |\n",
    "| `months_into_term`             | Public opinion often evolves ‚Äúwithin‚Äëterm‚Äù.                    | Reset to 0 at inauguration (Jan‚Äë2017, Jan‚Äë2025). |\n",
    "| `is_election_year`             | Approval swings in election years.                             | `Year.isin({2020,‚ÄØ2024,‚ÄØ2028})`                  |\n",
    "| `term` (0‚ÄØ=‚ÄØfirst,‚ÄØ1‚ÄØ=‚ÄØsecond) | Lets coefficients shift between terms; add interactions later. | `Year¬†‚â•¬†2025`                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4ce1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t\"] = (df[\"Year\"] - 2017) * 12 + (df[\"Month\"] - 1)\n",
    "df[\"months_into_term\"] = np.where(df[\"Year\"] < 2025,\n",
    "                                  df[\"t\"],                       # first term\n",
    "                                  df[\"t\"] - ((2025-2017)*12))    # second term reset\n",
    "df[\"sin_month\"]         = np.sin(2*np.pi*df[\"Month\"]/12)\n",
    "df[\"cos_month\"]         = np.cos(2*np.pi*df[\"Month\"]/12)\n",
    "df[\"is_election_year\"]  = df[\"Year\"].isin([2020, 2024, 2028]).astype(int)\n",
    "df[\"term\"]              = (df[\"Year\"] >= 2025).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b13ee",
   "metadata": {},
   "source": [
    "| Feature                        | Notes                                           |\n",
    "| ------------------------------ | ----------------------------------------------- |\n",
    "| `approve_lag1`, `approve_lag3` | 1‚Äë and 3‚Äëmonth lags (autoregressive signal).    |\n",
    "| `approve_ma3`                  | 3‚Äëmonth centred moving average (smooths noise). |\n",
    "| `approve_diff1`                | Month‚Äëto‚Äëmonth change¬†(Œî).                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41771087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"Year\", \"Month\", \"Source\"])\n",
    "df[\"approve_lag1\"] = df.groupby(\"Source\")[\"Approve\"].shift(1)\n",
    "df[\"approve_ma3\"]  = (df.groupby(\"Source\")[\"Approve\"]\n",
    "                        .transform(lambda s: s.rolling(3, min_periods=1).mean()))\n",
    "df[\"approve_diff1\"] = df[\"Approve\"] - df[\"approve_lag1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef513f",
   "metadata": {},
   "source": [
    "| Base series         | Expanded features                                             |\n",
    "| ------------------- | ------------------------------------------------------------- |\n",
    "| Unemployment rate   | Œî1, Œî12 (year‚Äëon‚Äëyear); 3‚Äëmo MA                               |\n",
    "| Consumer sentiment  | Same transforms                                               |\n",
    "| Dollar index        | Same transforms                                               |\n",
    "| **Composite index** | `econ_anxiety = z(Unemp) ‚Äì¬†z(Sentiment)` (z‚Äëscore each first) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f46d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_cols = [\"Unemployment_rate\",\n",
    "              \"Consumer_Index_Sentiment\",\n",
    "              \"Real_Broad_Dollar_Index\"]\n",
    "\n",
    "for col in macro_cols:\n",
    "    df[f\"{col}_diff1\"] = df[col] - df[col].shift(1)\n",
    "    df[f\"{col}_ma3\"]   = df[col].rolling(3, min_periods=1).mean()\n",
    "\n",
    "# Composite ‚Äúeconomic anxiety‚Äù index\n",
    "df_z = df[macro_cols].apply(lambda x: (x - x.mean())/x.std())\n",
    "df[\"econ_anxiety\"] = df_z[\"Unemployment_rate\"] - df_z[\"Consumer_Index_Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8de0206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118859/1402243563.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(approve_consensus=g[\"Approve\"].mean()))\n"
     ]
    }
   ],
   "source": [
    "df = (df.groupby([\"Year\",\"Month\"])\n",
    "        .apply(lambda g: g.assign(approve_consensus=g[\"Approve\"].mean()))\n",
    "        .reset_index(drop=True))\n",
    "df[\"source_deviation\"] = df[\"Approve\"] - df[\"approve_consensus\"]\n",
    "\n",
    "# One‚Äëhot for polling house\n",
    "df = pd.get_dummies(df, columns=[\"Source\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0b1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tagore/miniconda3/envs/stat165/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/home/tagore/miniconda3/envs/stat165/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/home/tagore/miniconda3/envs/stat165/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:1342: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                Approve   No. Observations:                  293\n",
      "Model:                            GLM   Df Residuals:                      242\n",
      "Model Family:                Gaussian   Df Model:                           50\n",
      "Link Function:               Identity   Scale:                      3.0606e-27\n",
      "Method:                          IRLS   Log-Likelihood:                 8011.6\n",
      "Date:                Mon, 05 May 2025   Deviance:                   3.0506e-23\n",
      "Time:                        19:47:52   Pearson chi2:                 3.05e-23\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================================================\n",
      "                                                                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                                     -6.119e-17   1.29e-19   -472.783      0.000   -6.14e-17   -6.09e-17\n",
      "Year                                                                       1.636e-17   1.75e-16      0.094      0.925   -3.26e-16    3.59e-16\n",
      "Month                                                                     -6.279e-16   2.34e-15     -0.268      0.788   -5.21e-15    3.96e-15\n",
      "Disapprove                                                                 6.082e-16   2.43e-15      0.250      0.802   -4.15e-15    5.37e-15\n",
      "Unemployment_rate                                                          9.232e-15   1.26e-14      0.735      0.462   -1.54e-14    3.38e-14\n",
      "Consumer_Index_Sentiment                                                   1.021e-14   7.34e-15      1.392      0.164   -4.17e-15    2.46e-14\n",
      "Real_Broad_Dollar_Index                                                    2.577e-15   2.21e-14      0.117      0.907   -4.08e-14    4.59e-14\n",
      "t                                                                         -6.386e-16   7.06e-16     -0.905      0.366   -2.02e-15    7.45e-16\n",
      "months_into_term                                                          -3.178e-16   7.47e-16     -0.426      0.670   -1.78e-15    1.15e-15\n",
      "sin_month                                                                 -1.204e-14   1.05e-14     -1.149      0.250   -3.26e-14    8.49e-15\n",
      "cos_month                                                                 -1.013e-15   6.51e-15     -0.156      0.876   -1.38e-14    1.17e-14\n",
      "is_election_year                                                           1.678e-14   2.82e-14      0.595      0.552   -3.85e-14     7.2e-14\n",
      "term                                                                       3.845e-17   1.36e-17      2.828      0.005    1.18e-17    6.51e-17\n",
      "approve_lag1                                                                  0.5000   2.56e-15   1.95e+14      0.000       0.500       0.500\n",
      "approve_ma3                                                               -1.174e-15   4.58e-15     -0.256      0.798   -1.01e-14     7.8e-15\n",
      "approve_diff1                                                                 0.5000   1.45e-15   3.45e+14      0.000       0.500       0.500\n",
      "Unemployment_rate_diff1                                                   -1.042e-14   1.48e-14     -0.704      0.482   -3.94e-14    1.86e-14\n",
      "Unemployment_rate_ma3                                                     -1.978e-14   2.14e-14     -0.923      0.356   -6.18e-14    2.22e-14\n",
      "Consumer_Index_Sentiment_diff1                                            -2.614e-15   5.01e-15     -0.522      0.602   -1.24e-14     7.2e-15\n",
      "Consumer_Index_Sentiment_ma3                                              -4.119e-15   7.24e-15     -0.569      0.569   -1.83e-14    1.01e-14\n",
      "Real_Broad_Dollar_Index_diff1                                              2.487e-15   1.61e-14      0.155      0.877    -2.9e-14     3.4e-14\n",
      "Real_Broad_Dollar_Index_ma3                                               -7.381e-15   2.21e-14     -0.334      0.738   -5.06e-14    3.59e-14\n",
      "econ_anxiety                                                               7.078e-15   9.36e-15      0.756      0.450   -1.13e-14    2.54e-14\n",
      "approve_consensus                                                             0.5000   2.87e-15   1.74e+14      0.000       0.500       0.500\n",
      "source_deviation                                                              0.5000   2.03e-15   2.46e+14      0.000       0.500       0.500\n",
      "Source_ActiVote                                                           -1.172e-13   7.09e-14     -1.652      0.098   -2.56e-13    2.18e-14\n",
      "Source_American Research Group                                            -9.914e-14   6.48e-14     -1.531      0.126   -2.26e-13    2.78e-14\n",
      "Source_AtlasIntel                                                         -4.607e-14   6.92e-14     -0.666      0.505   -1.82e-13    8.95e-14\n",
      "Source_Beacon Research/Shaw & Company Research                            -7.727e-14   8.19e-14     -0.944      0.345   -2.38e-13    8.32e-14\n",
      "Source_Big Data Poll                                                       3.258e-18    6.8e-29   4.79e+10      0.000    3.26e-18    3.26e-18\n",
      "Source_Blueprint Polling                                                  -1.316e-13   8.15e-14     -1.614      0.106   -2.91e-13    2.82e-14\n",
      "Source_Bravo Group                                                        -1.052e-13   7.99e-14     -1.316      0.188   -2.62e-13    5.15e-14\n",
      "Source_CNN/SSRS                                                           -9.373e-14    6.7e-14     -1.398      0.162   -2.25e-13    3.77e-14\n",
      "Source_Civiqs                                                             -6.922e-14    6.7e-14     -1.032      0.302   -2.01e-13    6.22e-14\n",
      "Source_Clarity Campaign Labs                                               -1.03e-13   7.32e-14     -1.406      0.160   -2.46e-13    4.06e-14\n",
      "Source_Cygnal Political                                                   -8.749e-14   6.93e-14     -1.263      0.207   -2.23e-13    4.83e-14\n",
      "Source_Echelon Insights                                                   -9.028e-14   6.77e-14     -1.333      0.182   -2.23e-13    4.24e-14\n",
      "Source_Emerson College                                                    -1.073e-13   6.69e-14     -1.603      0.109   -2.39e-13    2.39e-14\n",
      "Source_Fabrizio Ward/Impact Research                                      -2.328e-18    1.2e-29  -1.94e+11      0.000   -2.33e-18   -2.33e-18\n",
      "Source_Fabrizio, Lee & Associates/Impact Research                          3.378e-18   1.36e-29   2.48e+11      0.000    3.38e-18    3.38e-18\n",
      "Source_Gallup                                                             -9.608e-14   6.48e-14     -1.484      0.138   -2.23e-13    3.08e-14\n",
      "Source_HarrisX                                                            -2.031e-18   1.06e-29  -1.92e+11      0.000   -2.03e-18   -2.03e-18\n",
      "Source_HarrisX/Harris Poll                                                -7.313e-14   7.49e-14     -0.977      0.329    -2.2e-13    7.36e-14\n",
      "Source_Hart Research Associates/Public Opinion Strategies                 -1.027e-13   8.17e-14     -1.257      0.209   -2.63e-13    5.74e-14\n",
      "Source_InsiderAdvantage                                                     8.51e-19   8.75e-30   9.73e+10      0.000    8.51e-19    8.51e-19\n",
      "Source_Ipsos                                                              -7.928e-14   6.11e-14     -1.297      0.195   -1.99e-13    4.06e-14\n",
      "Source_J.L. Partners                                                      -9.572e-14   6.67e-14     -1.435      0.151   -2.26e-13     3.5e-14\n",
      "Source_Justice Research Fund                                               -3.31e-19   6.58e-30  -5.03e+10      0.000   -3.31e-19   -3.31e-19\n",
      "Source_Marist College                                                       -7.6e-14   6.69e-14     -1.136      0.256   -2.07e-13    5.52e-14\n",
      "Source_Marquette Law School                                               -3.364e-19   1.21e-29  -2.79e+10      0.000   -3.36e-19   -3.36e-19\n",
      "Source_McLaughlin & Associates                                            -8.594e-14   8.42e-14     -1.021      0.307   -2.51e-13     7.9e-14\n",
      "Source_Mitchell Research & Communications                                   3.01e-31   4.13e-30      0.073      0.942   -7.79e-30     8.4e-30\n",
      "Source_Morning Consult                                                     -9.93e-14   6.26e-14     -1.586      0.113   -2.22e-13    2.34e-14\n",
      "Source_Navigator Research                                                 -9.482e-14    6.6e-14     -1.436      0.151   -2.24e-13    3.46e-14\n",
      "Source_Noble Predictive Insights                                          -7.917e-14    8.3e-14     -0.954      0.340   -2.42e-13    8.35e-14\n",
      "Source_North Star Opinion Research                                                 0          0        nan        nan           0           0\n",
      "Source_Pew Research Center                                                         0          0        nan        nan           0           0\n",
      "Source_Quantus Insights                                                   -7.643e-14   6.66e-14     -1.147      0.251   -2.07e-13    5.42e-14\n",
      "Source_Quinnipiac University                                              -8.779e-14   6.68e-14     -1.315      0.189   -2.19e-13    4.31e-14\n",
      "Source_RMG Research                                                       -1.295e-13   6.64e-14     -1.949      0.051    -2.6e-13    7.21e-16\n",
      "Source_RealClear Opinion Research                                                  0          0        nan        nan           0           0\n",
      "Source_Remington                                                                   0          0        nan        nan           0           0\n",
      "Source_Research Co.                                                                0          0        nan        nan           0           0\n",
      "Source_SurveyUSA                                                                   0          0        nan        nan           0           0\n",
      "Source_TIPP Insights                                                      -8.746e-14   6.61e-14     -1.323      0.186   -2.17e-13    4.21e-14\n",
      "Source_Targoz Market Research                                                      0          0        nan        nan           0           0\n",
      "Source_The Bullfinch Group                                                -7.383e-14    6.8e-14     -1.085      0.278   -2.07e-13    5.95e-14\n",
      "Source_The New York Times/Siena College                                            0          0        nan        nan           0           0\n",
      "Source_Trafalgar Group/InsiderAdvantage                                   -4.025e-14    7.6e-14     -0.530      0.596   -1.89e-13    1.09e-13\n",
      "Source_University of Massachusetts Department of Political Science/YouGov          0          0        nan        nan           0           0\n",
      "Source_University of New Hampshire                                        -8.205e-14   6.43e-14     -1.277      0.202   -2.08e-13    4.39e-14\n",
      "Source_YouGov                                                             -9.421e-14   6.05e-14     -1.557      0.119   -2.13e-13    2.44e-14\n",
      "Source_co/efficient                                                                0          0        nan        nan           0           0\n",
      "=============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_mask = (df[\"Year\"] < 2025) | ((df[\"Year\"] == 2025) & (df[\"Month\"] <= 5))\n",
    "df_train   = df.loc[train_mask].copy()\n",
    "\n",
    "feature_cols = [c for c in df.columns\n",
    "                if c not in [\"Approve\", \"Politicican\", \"No_Oppinion\"]]\n",
    "\n",
    "X_train = sm.add_constant(df_train[feature_cols])\n",
    "\n",
    "\n",
    "y_train = df_train[\"Approve\"]\n",
    "\n",
    "bool_cols = X_train.select_dtypes(bool).columns\n",
    "X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
    "\n",
    "# (b)  force everything else to numeric, turning non‚Äëparsible entries into NaN\n",
    "X_train = X_train.apply(pd.to_numeric, errors=\"coerce\")\n",
    "good = X_train.notna().all(axis=1) & y_train.notna()\n",
    "X_train, y_train = X_train.loc[good], y_train.loc[good]\n",
    "# -------------------------------------------------\n",
    "# 7.  Fit GLM (use Gaussian for simplicity)\n",
    "# -------------------------------------------------\n",
    "glm = sm.GLM(y_train, X_train, family=sm.families.Gaussian()).fit()\n",
    "ridge10 = sm.OLS(y_train, X_train).fit_regularized(alpha=10, refit=True)\n",
    "print(glm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e955db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Trump approval (Gallup‚Äëstyle) for June¬†2025: 45.00%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 8.  Build the June‚Äë2025 predictor row\n",
    "# -------------------------------------------------\n",
    "june_mask = (df[\"Year\"] == 2025) & (df[\"Month\"] == 6)\n",
    "\n",
    "if june_mask.any():                        # June already in the CSV\n",
    "    pred_df = df.loc[june_mask].copy()\n",
    "else:                                      # create one from May‚Äë2025\n",
    "    pred_df = (df.loc[(df[\"Year\"] == 2025) & (df[\"Month\"] == 5)]\n",
    "                 .iloc[[0]]                # keep as DataFrame\n",
    "                 .copy())\n",
    "\n",
    "    # --- bump time features ---\n",
    "    pred_df[\"Month\"] = 6\n",
    "    pred_df[\"t\"]    += 1\n",
    "    pred_df[\"months_into_term\"] += 1\n",
    "    pred_df[\"sin_month\"] = np.sin(2*np.pi*6/12)\n",
    "    pred_df[\"cos_month\"] = np.cos(2*np.pi*6/12)\n",
    "\n",
    "    # --- OPTIONAL: plug in macro forecasts ---\n",
    "    # pred_df[\"Unemployment_rate\"]        = 4.0\n",
    "    # pred_df[\"Consumer_Index_Sentiment\"] = 85.0\n",
    "    # pred_df[\"Real_Broad_Dollar_Index\"]  = 104.0\n",
    "\n",
    "    # refresh diff‚Äâ/‚ÄâMA transforms\n",
    "    for col in macro_cols:\n",
    "        pred_df[f\"{col}_diff1\"] = pred_df[col] - df[col].iloc[-1]\n",
    "        pred_df[f\"{col}_ma3\"]   = pd.concat([df[col].tail(2),\n",
    "                                             pred_df[col]]).mean()\n",
    "\n",
    "    # recompute composite index\n",
    "    pred_df[\"econ_anxiety\"] = (\n",
    "        (pred_df[\"Unemployment_rate\"] - df[\"Unemployment_rate\"].mean())\n",
    "        / df[\"Unemployment_rate\"].std()\n",
    "        -\n",
    "        (pred_df[\"Consumer_Index_Sentiment\"] - df[\"Consumer_Index_Sentiment\"].mean())\n",
    "        / df[\"Consumer_Index_Sentiment\"].std()\n",
    "    )\n",
    "\n",
    "    # lagged approval placeholders (optional fine‚Äëtuning)\n",
    "    pred_df[\"approve_lag1\"]  = pred_df[\"Approve\"]        # assumes flat\n",
    "    pred_df[\"approve_diff1\"] = 0\n",
    "    pred_df[\"approve_ma3\"]   = pred_df[\"Approve\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9.  Pollster consensus / deviation for June\n",
    "# -------------------------------------------------\n",
    "pred_df[\"approve_consensus\"] = pred_df.groupby([\"Year\",\"Month\"])[\"Approve\"].transform(\"mean\")\n",
    "pred_df[\"source_deviation\"]  = pred_df[\"Approve\"] - pred_df[\"approve_consensus\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10.  Re‚Äëbuild Source_* dummies so columns match X_train\n",
    "# -------------------------------------------------\n",
    "for col in [c for c in X_train.columns if c.startswith(\"Source_\")]:\n",
    "    pollster = col.replace(\"Source_\", \"\")\n",
    "    if col not in pred_df.columns:               # column was dropped earlier\n",
    "        pred_df[col] = 0\n",
    "    if \"Source\" in pred_df.columns:              # normal case\n",
    "        pred_df[col] = (pred_df[\"Source\"] == pollster).astype(int)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 11.  Final column alignment & coercion\n",
    "# -------------------------------------------------\n",
    "X_june = (pred_df.reindex(columns=X_train.columns.drop(\"const\"), fill_value=0)\n",
    "                    .apply(pd.to_numeric, errors=\"coerce\")\n",
    "                    .fillna(0))\n",
    "\n",
    "X_june = sm.add_constant(X_june, has_constant=\"add\")\n",
    "X_june = X_june.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 12.  Predict June‚Äë2025 approval\n",
    "# -------------------------------------------------\n",
    "pred = glm.predict(X_june)\n",
    "print(f\"\\nPredicted Trump approval (Gallup‚Äëstyle) for June¬†2025: {pred.iloc[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b465d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:25<00:00, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "June‚Äë2025 approval (ridge): 44.97%  ‚Äî 80‚ÄØ% bootstrap CI: 44.91¬†‚Äì¬†45.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "B      = 500           # bootstrap replications\n",
    "alpha  = 0.10          # 80‚ÄØ% CI  ‚áí 10th & 90th pct.\n",
    "lambda_ = 10           # same ridge penalty\n",
    "\n",
    "months = df_train[[\"Year\", \"Month\"]].drop_duplicates().values\n",
    "boot_preds = []\n",
    "\n",
    "for _ in trange(B):\n",
    "    # --- resample months with replacement ---\n",
    "    rows = pd.concat([df_train[(df_train[\"Year\"] == y) & (df_train[\"Month\"] == m)]\n",
    "                      for y, m in months[np.random.choice(len(months),\n",
    "                                                           size=len(months),\n",
    "                                                           replace=True)]],\n",
    "                     ignore_index=True)\n",
    "\n",
    "    Xb = rows[feature_cols]; yb = rows[\"Approve\"]\n",
    "    Xb = sm.add_constant(Xb).apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    mdl = Ridge(alpha=lambda_, fit_intercept=False).fit(Xb.values, yb.values)\n",
    "    boot_preds.append(mdl.predict(X_june.values)[0])\n",
    "\n",
    "boot_preds = np.array(boot_preds)\n",
    "point = boot_preds.mean()\n",
    "lo, hi = np.percentile(boot_preds, [100*alpha/2, 100*(1-alpha/2)])\n",
    "\n",
    "print(f\"June‚Äë2025 approval (ridge): {point:.2f}%  ‚Äî 80‚ÄØ% bootstrap CI: {lo:.2f}¬†‚Äì¬†{hi:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d550d",
   "metadata": {},
   "source": [
    "Thought for a couple of seconds\n",
    "\n",
    "\n",
    "**High‚Äëlevel idea of the bootstrap script**\n",
    "\n",
    "1. **Choose settings**\n",
    "\n",
    "* `B = 500` ‚Üí run 500 bootstrap replications.\n",
    "* `alpha = 0.20` ‚Üí we want an 80‚ÄØ% confidence interval (the 10th and 90th percentiles).\n",
    "* `ridge = 5.0` ‚Üí add a small L2 penalty so each refit can‚Äôt perfectly over‚Äëfit the data.\n",
    "\n",
    "2. **Resample the data 500‚ÄØtimes**\n",
    "\n",
    "* Treat *one calendar month* as the atomic unit.\n",
    "* For every replication, draw the same number of months as in the original sample, **with replacement**.\n",
    "* Collect every poll that belongs to each chosen month to build a new dataset.\n",
    "\n",
    "3. **Refit the model on each resampled dataset**\n",
    "\n",
    "* Re‚Äëcreate the design matrix (`Xb`) and target vector (`yb`).\n",
    "* Drop any rows with missing numbers.\n",
    "* Fit either a ridge regression (if `ridge‚ÄØ>‚ÄØ0`) or an ordinary OLS.\n",
    "* Use that model to predict Trump‚Äôs approval for June‚ÄØ2025 (`X_june`).\n",
    "* Store the prediction in `boot_preds`.\n",
    "\n",
    "4. **Convert the 500 predictions into an interval**\n",
    "\n",
    "* Mean of the 500 numbers ‚Üí bootstrap point estimate.\n",
    "* 10th percentile ‚Üí lower bound of the 80‚ÄØ% CI.\n",
    "* 90th percentile ‚Üí upper bound.\n",
    "\n",
    "5. **Print the result**\n",
    "\n",
    "```\n",
    "Bootstrap point estimate (mean of 500 reps):  <point> %\n",
    "80% bootstrap CI: [<lower> %, <upper> %]\n",
    "```\n",
    "\n",
    "**Why it works**\n",
    "The month‚Äëlevel resampling makes coefficients and predictions wobble in a way that mimics real‚Äëworld sampling variability, so the spread of the 500 forecasts becomes a non‚Äëparametric confidence interval around the June‚Äë2025 prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472cf310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:28<00:00, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bootstrap point estimate (mean of 500 reps): 44.99%\n",
      "80% bootstrap CI: [44.98%, 45.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "B      = 500      # number of bootstrap replications\n",
    "alpha  = 0.20     # 80% CI  ‚áí  10th & 90th percentiles\n",
    "ridge  = 5.0      # small Œª to avoid perfect fit; set 0 for plain OLS\n",
    "\n",
    "# 1) list of unique (Year,Month) in the training window\n",
    "months = df_train[[\"Year\", \"Month\"]].drop_duplicates().values\n",
    "\n",
    "boot_preds = []\n",
    "\n",
    "for _ in trange(B, desc=\"Bootstrapping\"):\n",
    "    # 2) resample months with replacement\n",
    "    sample_idx = np.random.choice(len(months), size=len(months), replace=True)\n",
    "    boot_rows  = pd.concat(\n",
    "        [df_train.loc[(df_train[\"Year\"] == months[i][0]) &\n",
    "                      (df_train[\"Month\"] == months[i][1])]\n",
    "         for i in sample_idx],\n",
    "        ignore_index=True)\n",
    "\n",
    "    # 3) rebuild X / y for this bootstrap\n",
    "    Xb = sm.add_constant(boot_rows[feature_cols])\n",
    "    yb = boot_rows[\"Approve\"]\n",
    "\n",
    "    # numerics only, drop rows with any NaN\n",
    "    bool_cols = Xb.select_dtypes(bool).columns\n",
    "    Xb[bool_cols] = Xb[bool_cols].astype(int)\n",
    "    Xb = Xb.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    good = Xb.notna().all(axis=1) & yb.notna()\n",
    "    Xb, yb = Xb.loc[good], yb.loc[good]\n",
    "\n",
    "    # 4) fit (Ridge ‚âà OLS if ridge=0)\n",
    "    if ridge > 0:\n",
    "        mdl = Ridge(alpha=ridge, fit_intercept=False)   # const already in Xb\n",
    "        mdl.fit(Xb.values, yb.values)\n",
    "        pred = mdl.predict(X_june.values)[0]\n",
    "    else:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")             # ignore cond num warnings\n",
    "            mdl = sm.OLS(yb, Xb).fit()\n",
    "        pred = mdl.predict(X_june)[0]\n",
    "\n",
    "    boot_preds.append(pred)\n",
    "\n",
    "boot_preds = np.array(boot_preds)\n",
    "lower = np.percentile(boot_preds, 100*alpha/2)\n",
    "upper = np.percentile(boot_preds, 100*(1-alpha/2))\n",
    "point = boot_preds.mean()\n",
    "\n",
    "print(f\"\\nBootstrap point estimate (mean of {B} reps): {point:5.2f}%\")\n",
    "print(f\"80% bootstrap CI: [{lower:5.2f}%, {upper:5.2f}%]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f96d7",
   "metadata": {},
   "source": [
    "Thought for a couple of seconds\n",
    "\n",
    "\n",
    "### High‚Äëlevel overview of the block‚Äëbootstrap forecasting code\n",
    "\n",
    "1. **Goal**\n",
    "   Produce a *realistic* 80‚ÄØ% prediction interval (PI) for Donald‚ÄØTrump‚Äôs Gallup approval in **June‚ÄØ2025**, accounting for\n",
    "\n",
    "   * parameter uncertainty,\n",
    "   * short‚Äëterm autocorrelation in monthly data, and\n",
    "   * Gallup‚Äôs own sampling error.\n",
    "\n",
    "2. **Key ingredients**\n",
    "\n",
    "   | Symbol             | Meaning                                                                     |\n",
    "   | ------------------ | --------------------------------------------------------------------------- |\n",
    "   | `B‚ÄØ=‚ÄØ1000`         | number of bootstrap replications                                            |\n",
    "   | `block_k‚ÄØ=‚ÄØ3`      | resample **3‚Äëmonth blocks** to keep local time‚Äëdependence intact            |\n",
    "   | `Œª‚ÄØ=‚ÄØ10`           | ridge penalty that prevents over‚Äëfitting inside each resample               |\n",
    "   | `poll_se‚ÄØ=‚ÄØ1.5‚ÄØpp` | extra ¬±1.5‚ÄØpercentage‚Äëpoint noise reflecting Gallup‚Äôs survey sampling error |\n",
    "\n",
    "3. **Workflow per replication**\n",
    "\n",
    "   1. **Resample months** ‚Äî draw random starting indices and glue together 3‚Äëmonth blocks until you rebuild a full history (with replacement).\n",
    "   2. **Refit model** ‚Äî run a ridge regression on that resampled dataset.\n",
    "   3. **Predict June‚ÄØ2025** using the fitted ridge coefficients.\n",
    "   4. **Add survey noise** ‚Äî jitter the prediction by one random draw from ùí©(0,‚ÄØpoll\\_se¬≤).\n",
    "   5. **Store the result** in the list `boot_pred`.\n",
    "\n",
    "4. **After all replications**\n",
    "\n",
    "   * Convert `boot_pred` ‚Üí NumPy array.\n",
    "   * **Point estimate** = mean of the 1‚ÄØ000 predictions.\n",
    "   * **80‚ÄØ% PI** = 10th and 90th percentiles of that distribution.\n",
    "   * Print:\n",
    "\n",
    "     ```\n",
    "     June‚Äë2025 Gallup approval: <mean>%   (80% PI: <lo>%¬†‚Äì¬†<hi>%)\n",
    "     ```\n",
    "\n",
    "5. **Why it matters**\n",
    "   *Moving‚Äëblock bootstrapping* captures serial correlation that plain IID resampling would miss.\n",
    "   **Ridge** keeps the model stable when a resample omits rare pollster dummies.\n",
    "   **Sampling‚Äëerror noise** widens the band to honor the fact that each Gallup poll is itself a sample.\n",
    "\n",
    "The end result is a prediction interval that reflects *all three* major uncertainty sources‚Äîmodel fit, month‚Äëto‚Äëmonth shocks, and polling error‚Äîyielding a far more credible range than the vanishing‚Äëwidth interval produced by an over‚Äëfit OLS model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 174/1000 [00:09<00:43, 19.15it/s]"
     ]
    }
   ],
   "source": [
    "B        = 1000        # replications\n",
    "alpha    = 0.10        # 80% PI\n",
    "lambda_  = 10         # ridge penalty\n",
    "block_k  = 15          # 3‚Äëmonth moving blocks\n",
    "poll_se  = 3         # sampling error of a single Gallup poll (pp)\n",
    "\n",
    "months   = df_train[[\"Year\",\"Month\"]].drop_duplicates().values\n",
    "boot_pred = []\n",
    "\n",
    "for _ in trange(B):\n",
    "    # -- draw starting indices for moving blocks\n",
    "    starts = np.random.randint(0, len(months)-block_k+1,\n",
    "                               size=len(months)//block_k + 1)\n",
    "    rows = pd.concat([df_train[(df_train[\"Year\"]==months[i+j][0]) &\n",
    "                               (df_train[\"Month\"]==months[i+j][1])]\n",
    "                      for i in starts for j in range(block_k)],\n",
    "                     ignore_index=True)\n",
    "\n",
    "    Xb = sm.add_constant(rows[feature_cols]).apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    yb = rows[\"Approve\"]\n",
    "\n",
    "    mdl = Ridge(alpha=lambda_, fit_intercept=False).fit(Xb.values, yb.values)\n",
    "    mu  = mdl.predict(X_june.values)[0]\n",
    "\n",
    "    # add Gallup sampling error\n",
    "    mu += np.random.normal(scale=poll_se)\n",
    "\n",
    "    boot_pred.append(mu)\n",
    "\n",
    "# centre & percentiles\n",
    "boot_pred = np.array(boot_pred)\n",
    "pt   = boot_pred.mean()\n",
    "lo, hi = np.percentile(boot_pred, [100*alpha/2, 100*(1-alpha/2)])\n",
    "\n",
    "print(f\"June‚Äë2025 Gallup approval: {pt:4.1f}%   (80% PI: {lo:4.1f}¬†‚Äì¬†{hi:4.1f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat165",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
